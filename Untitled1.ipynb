{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([data.columns[0],data.columns[32]],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diagnosis'].replace(to_replace=['B','M'],value=[0,1],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data.iloc[0:int(0.7*len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = data.iloc[int(0.7*len(data)):int(0.9*len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = data.iloc[int(0.9*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(training_data['diagnosis']).reshape(training_data['diagnosis'].shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transpose = np.array(training_data.drop(['diagnosis'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transpose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transpose = (X_transpose - np.mean(X_transpose,axis=0))/np.std(X_transpose,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = X_transpose.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X_transpose.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Posterior(theta0,theta,X_transpose):\n",
    "    discriminant_score = theta0 + np.matmul(X_transpose,theta)\n",
    "    P_theta0_theta = 1/(1 + np.exp(-discriminant_score))\n",
    "    return P_theta0_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_loss(train_labels,P_theta0_theta,theta,reg_strength):\n",
    "    lhs_sum = np.matmul(train_labels.T,np.log(P_theta0_theta))\n",
    "    rhs_sum = np.matmul((1-train_labels).T,np.log(1-P_theta0_theta))\n",
    "    neg_log_loss_theta0_theta = -(1/train_labels.shape[0])*(lhs_sum + rhs_sum)+(reg_strength*np.linalg.norm(theta)/2)\n",
    "    return neg_log_loss_theta0_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going to train Logistic Regression in Mini Batch Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(step_size,reg_strength):\n",
    "    theta0_initial = 0\n",
    "    theta_initial = np.zeros((m,1))\n",
    "    epsilon = step_size\n",
    "    tol = 10**(-6)\n",
    "    iterations = list()\n",
    "    neg_log_loss_history = list()\n",
    "    iteration_number = 0\n",
    "    mini_batch_size = 199\n",
    "    time_steps = N_train//mini_batch_size\n",
    "    epoch_counter = 0\n",
    "    invalid_value_flag = 0\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        for i in range(0,time_steps):\n",
    "            rand_indices = np.random.choice(a=np.arange(0,N_train),size=mini_batch_size,replace=False)\n",
    "            X_transpose_mini_batch = X_transpose[rand_indices]\n",
    "            train_labels_mini_batch = train_labels[rand_indices]\n",
    "\n",
    "            P_initial = Posterior(theta0_initial,theta_initial,X_transpose_mini_batch)\n",
    "            theta0_final = theta0_initial - epsilon*np.mean(P_initial - train_labels_mini_batch)\n",
    "            theta_final = theta_initial - epsilon*((1/mini_batch_size)*np.matmul(X_transpose_mini_batch.T,\n",
    "                                                (P_initial-train_labels_mini_batch))+reg_strength*theta_initial)\n",
    "                                                   \n",
    "\n",
    "            neg_log_loss_initial = neg_log_loss(train_labels_mini_batch,P_initial,theta_initial,reg_strength)\n",
    "\n",
    "            P_final = Posterior(theta0_final,theta_final,X_transpose_mini_batch)\n",
    "            neg_log_loss_final = neg_log_loss(train_labels_mini_batch,P_final,theta_final,reg_strength)\n",
    "            \n",
    "            if np.isnan(neg_log_loss_final[0][0]) == True:\n",
    "                invalid_value_flag = 1\n",
    "                break\n",
    "\n",
    "            theta0_initial = theta0_final\n",
    "            theta_initial = theta_final\n",
    "\n",
    "            iterations.append(iteration_number)\n",
    "            neg_log_loss_history.append(neg_log_loss_initial[0][0])\n",
    "\n",
    "            iteration_number = iteration_number + 1\n",
    "\n",
    "        epoch_counter = epoch_counter + 1\n",
    "\n",
    "        if abs(neg_log_loss_initial - neg_log_loss_final) < tol or invalid_value_flag == 11:\n",
    "            print(\"\\n\\nEpochs =\",epoch_counter,\"Cross Entropy Loss =\",neg_log_loss_initial[0][0],\"\\n\\n\")\n",
    "            break\n",
    "            \n",
    "    return {(step_size,reg_strength):[theta0_final,theta_final]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(theta0,theta,X_transpose,labels):\n",
    "    P_mini_batch = Posterior(theta0,theta,X_transpose)\n",
    "    Predicted_labels = P_mini_batch > 0.5 \n",
    "    accuracy = np.count_nonzero(Predicted_labels == labels)/labels.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = list()\n",
    "for step_size in [0.001,0.01]:\n",
    "    for reg_hyp_param in [0.0001,0.001,0.01,0.1,1,10,100]:\n",
    "        grid_search_results.append(fit(step_size,reg_hyp_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_labels = np.array(cv_data['diagnosis']).reshape(cv_data.shape[0],1)\n",
    "X_cv_transpose = np.array(cv_data.drop(['diagnosis'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv_transpose = (X_cv_transpose - np.mean(X_cv_transpose,axis=0))/np.std(X_cv_transpose,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv_results = dict()\n",
    "for configs in grid_search_results:\n",
    "    grid_search_cv_results[tuple(configs.keys())] = compute_accuracy(list(configs.values())[0][0],\n",
    "                                                                    list(configs.values())[0][1],\n",
    "                                                                    X_cv_transpose,cv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going to run Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_results = list()\n",
    "for i in range(10):\n",
    "    step_size = np.random.uniform(low=0.001,high=0.1)\n",
    "    reg_hyp_param = np.random.uniform(low=0.0001,high=10**6)\n",
    "    random_search_results.append(fit(step_size,reg_hyp_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
